{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T17:07:52.971337Z",
     "start_time": "2024-02-04T17:07:52.365663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------------+----------------+------------------+------------------+\n",
      "|year|week|PULocationID|total_passengers|    total_distance|      total_amount|\n",
      "+----+----+------------+----------------+------------------+------------------+\n",
      "|2018|   1|           1|             296|            335.08|16448.950000000015|\n",
      "|2018|   1|           2|               1|               7.2|              23.3|\n",
      "|2018|   1|           3|              22|             99.02|349.44000000000005|\n",
      "|2018|   1|           4|            7763|11798.969999999996| 65709.18999999891|\n",
      "|2018|   1|           5|               2|                 0|            120.96|\n",
      "|2018|   1|           6|               8| 4.779999999999999|            156.02|\n",
      "|2018|   1|           7|            6632|10860.950000000006| 54907.89999999894|\n",
      "|2018|   1|           8|              42|159.67000000000004|1168.2599999999998|\n",
      "|2018|   1|           9|              27|            105.83|             414.2|\n",
      "|2018|   1|          10|             776|           6749.07|28696.480000000018|\n",
      "|2018|   1|          11|              32|             189.4|            708.85|\n",
      "|2018|   1|          12|            1919|           4433.02|19824.250000000084|\n",
      "|2018|   1|          13|           23977|54255.630000000005| 252748.4300000116|\n",
      "|2018|   1|          14|             193|            618.48|2984.9199999999987|\n",
      "|2018|   1|          15|               4|              6.27|              33.7|\n",
      "|2018|   1|          16|              27|            104.36|            421.76|\n",
      "|2018|   1|          17|             791|1330.8000000000002| 7150.619999999999|\n",
      "|2018|   1|          18|              62|            150.72| 736.6500000000002|\n",
      "|2018|   1|          19|              33|            116.65|             471.3|\n",
      "|2018|   1|          20|              36|              56.6|            313.85|\n",
      "+----+----+------------+----------------+------------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_file_path = \"/Users/pintoza/Desktop/dev/data-science/taxi-demand-forecast/data/interim/weekly_zone_aggregates.csv\"\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Taxi Data Analysis\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = spark.read.option(\"header\", \"true\").csv(csv_file_path)\n",
    "\n",
    "# Show the first few rows of the DataFrame to confirm loading\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------------+----------------+------------------+------------------+\n",
      "|year|week|PULocationID|total_passengers|    total_distance|      total_amount|\n",
      "+----+----+------------+----------------+------------------+------------------+\n",
      "|2019|  49|           1|             321|441.77000000000004|22832.130000000012|\n",
      "|2019|  49|           2|               2|              20.7|              78.6|\n",
      "|2019|  49|           3|              28| 363.5399999999999|1663.6400000000003|\n",
      "|2019|  49|           4|            4372| 7507.689999999993|51820.319999999556|\n",
      "|2019|  49|           5|               8|170.67000000000002|             516.9|\n",
      "|2019|  49|           6|               1|              14.5|              39.8|\n",
      "|2019|  49|           7|            2690|           5166.63|29075.559999999925|\n",
      "|2019|  49|           8|              21|             59.82|            853.11|\n",
      "|2019|  49|           9|              10|124.35999999999999|            723.96|\n",
      "|2019|  49|          10|             898| 9105.169999999995| 43577.93000000004|\n",
      "|2019|  49|          11|               7|216.29999999999998|           1169.29|\n",
      "|2019|  49|          12|            1117|2871.1800000000007|15506.730000000036|\n",
      "|2019|  49|          13|           23425| 63330.71000000008|354218.07000001287|\n",
      "|2019|  49|          14|             134|             800.3| 4910.329999999999|\n",
      "|2019|  49|          15|              23|200.72000000000003|1067.1599999999999|\n",
      "|2019|  49|          16|              19|189.57999999999998|1292.1299999999999|\n",
      "|2019|  49|          17|             247| 976.7499999999999| 5949.700000000006|\n",
      "|2019|  49|          18|              40|370.68000000000006|1830.8499999999995|\n",
      "|2019|  49|          19|              26|            218.55|           1672.27|\n",
      "|2019|  49|          20|              27|            172.84|           1049.12|\n",
      "+----+----+------------+----------------+------------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Step 1: Create a DataFrame of all year-week combinations\n",
    "year_week_df = df.select(\"year\", \"week\").distinct()\n",
    "\n",
    "# Step 2: Create a DataFrame of all PULocationIDs\n",
    "locations_df = spark.range(1, 266).withColumnRenamed(\"id\", \"PULocationID\")  # Assuming IDs 1 through 265\n",
    "\n",
    "# Step 3: Cross join to get all possible combinations\n",
    "all_combinations_df = year_week_df.crossJoin(locations_df)\n",
    "\n",
    "# Step 4: Left join with your original data\n",
    "combined_df = all_combinations_df.join(df, [\"year\", \"week\", \"PULocationID\"], \"left_outer\")\n",
    "\n",
    "# Step 5: Fill missing values with zeros\n",
    "final_df = combined_df.fillna({\"total_passengers\": 0, \"total_distance\": 0, \"total_amount\": 0})\n",
    "\n",
    "# Show the result\n",
    "final_df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T17:07:55.829707Z",
     "start_time": "2024-02-04T17:07:54.762881Z"
    }
   },
   "id": "49138baf86ce5ef8",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count: 69430\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows in the DataFrame\n",
    "row_count = final_df.count()\n",
    "print(f\"Row count: {row_count}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T17:07:57.746172Z",
     "start_time": "2024-02-04T17:07:57.104393Z"
    }
   },
   "id": "29ead3398cfd62eb",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate combinations count: 0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Group by year, week, and PULocationID and count each combination\n",
    "unique_combinations_df = final_df.groupBy(\"year\", \"week\", \"PULocationID\").agg(F.count(\"*\").alias(\"count\"))\n",
    "\n",
    "# Check for any combination that occurs more than once\n",
    "duplicate_combinations_count = unique_combinations_df.filter(\"count > 1\").count()\n",
    "\n",
    "print(f\"Duplicate combinations count: {duplicate_combinations_count}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T17:07:59.909665Z",
     "start_time": "2024-02-04T17:07:59.133826Z"
    }
   },
   "id": "79e7c10a7c3b9f3c",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------------+----------------+--------------+------------+\n",
      "|year|week|PULocationID|total_passengers|total_distance|total_amount|\n",
      "+----+----+------------+----------------+--------------+------------+\n",
      "|   0|   0|           0|               0|             0|           0|\n",
      "+----+----+------------+----------------+--------------+------------+\n"
     ]
    }
   ],
   "source": [
    "# Find number of missing values in each column\n",
    "final_df.select([F.count(F.when(F.isnull(c), c)).alias(c) for c in final_df.columns]).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T17:08:01.279486Z",
     "start_time": "2024-02-04T17:08:00.567852Z"
    }
   },
   "id": "ba66f454536c5022",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[('year', 'string'),\n ('week', 'string'),\n ('PULocationID', 'bigint'),\n ('total_passengers', 'string'),\n ('total_distance', 'string'),\n ('total_amount', 'string')]"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T17:08:02.007839Z",
     "start_time": "2024-02-04T17:08:02.000631Z"
    }
   },
   "id": "53f250288f8aac0f",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Convert to pandas DataFrame (note: be mindful of memory limitations)\n",
    "pandas_df = final_df.toPandas()\n",
    "\n",
    "# Save to CSV using pandas\n",
    "pandas_df.to_csv(\"/Users/pintoza/Desktop/dev/data-science/taxi-demand-forecast/data/processed/weekly_zone_aggregates.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T17:47:29.263726Z",
     "start_time": "2024-02-04T17:47:26.280177Z"
    }
   },
   "id": "5c82de898d10b19",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "94ccedfca5042548"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
